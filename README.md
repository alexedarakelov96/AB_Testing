# KnowledgeBaseAB-testing


## Оглавление
1. [Введение](#Введение)    
2. [Cuped](#Cuped)
3. [Стратификация](#Стратификация)
4. [Линериазация (с перевзвешиванием)](#Линериазация-(с-перевзвешиванием)) 
6. [Баесовская статистика и ML](#Баесовская-статистика-и-ML)
7. [Многорукие бандиты](#Многорукие-бандиты)
8. [Дельта-метод](#Дельта-метод)
9. [Техника бакетов](#Техника-бакетов)
10. [Peeking problem](#Peeking-problem)
11. [Множественное тестирование](#Множественное-тестирование)
12. [Бутстрап](#Бутстрап)

## Введение
  
Две группы

**Контрольная** - не изменяем ничего   
**Тестовая** - с изменениями    
**p-value** - вероятность получить для случайной величины такое же или более экстремальное значение статистики (среднего арифметического, медианы и др.), по сравнению с ранее наблюдаемым, при условии, что нулевая гипотеза верна.

Неверное утверждение p-value - вероятность, что **H0** верна

Статистика - любая (измеримая) функция от выборки.

 ![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/ab%20h0%20h1%20statistics.png)
 
Чтобы использовать t-критерий Стьюдента, данные должны подходить под следующие условия:
1. Данные должны иметь **Нормальное распределение**. Методов достаточно много. Один из самых используемых — это критерий Шапиро-Уилка.
2. **Дисперсии** в выборках должны быть **гомогенны**. Критерий Бартлета

Непарараметрический критерий Манна-Уитни. В случае анализа n>2 групп можно использовать критерий Краскела-Уоллиса.
____

## Cuped
Про стратификацию и Cuped хорошо рассказано в [докладе Яндекса](https://habr.com/ru/company/yandex/blog/497804/) и на [medium](https://medium.com/statistics-experiments/cuped-%D0%B8%D0%BB%D0%B8-%D1%83%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%87%D1%83%D0%B2%D1%81%D1%82%D0%B2%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%BA%D0%B8-de7183fc964c)
 ![ph1](https://hsto.org/webt/gp/ul/q8/gpulq8fgy0dm9s60p9dtfsnmegg.jpeg)

Cuped - для непрерывных величин.

![\Large ](https://latex.codecogs.com/svg.latex?\Large&space;\theta=cov(X,Y)/var(X))  

Для **дискретных величин** можно использовать **Стратификацию**  и
**Линеаризация** (в 30-40) раз. У него есть минус в том что он метрику переводит в другое признаковое пространство. Да, мы можем строго доказать, что новая метрика абсолютно пропорциональна изначальной метрики. И по нашим экспериментам - не было ложных прокрасок. Т.е. у нас альфа остается на изначально заданном уровне, а чувствительность повышается многократно.  
____

## Стратификация
1. Если берем взвешенное среднее, как среднее в каждой группе умноженное на пропорцию
Тогда **среднии сохранятся**, а **дисперсия уменьшится**.

Пострафикация - накладывание дополнительной информации уже постфактум (если знаем о разлициях между выборочной совокупностью и целевой.

* Коварата
Как искать группы?
- Если есть какой-то признак, который никак не связан с исследуемой величиной, он ничего не изменит. 
Поэтому он даже называется - **ковариация, ковариата**. Т.е. мы выбираем такой признак, который максимально сильно растаскивает наши группы по исследуемому признаку. И это уже вопрос к data mining. 
Netflix - по странам растаскивает ARPU очень хорошо. Т.е. есть ковариата, которая сильно корелирует с ARPU, и ее использовать.

Стратификация — метод выбора подмножества объектов из генеральной совокупности, разбитой на подмножества (страты).    

Находим величину или такой признак, по которому сможем разбивать на группы: разбиваем на К групп (К — это количество уникальных величин, количество групп).

![ph1](https://hsto.org/webt/r7/au/vg/r7auvglpkmo9b1a84skfarfrcdc.jpeg)
Дисперсия случайного сэмплирования может быть представлена в виде суммы дисперсии внутри группы стратифицированной, и между стратифицированными группами.
![ph1](https://hsto.org/webt/du/3u/a8/du3ua8hb-zrby4bzwzclzmq3vec.jpeg)

Также используется как для балансировки классов в кросс-валидации (или просто в разбиениях train/test split в несбалансированных классах)
____

## Линеаризация (с перевзвешиванием)
Для увеличения mde (minimum detectable effect).

https://www.youtube.com/watch?v=oEyves_VmnM

Первый доклад Нерсес Багиян (Moscow data sicenc major). 
![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/ab%20lin.png)
K - коэффициент CTR на контроле в группе А (в версии без изменений).
L(u) - ошибка относительно контроля (количество кликов - коэффициент CTR на контроле * количество показов)
Разница есть - CTR изменится пропорционально активности пользователя
![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/ab%20weighting2.png)

Корень - каждому пользователю придаем какой-то вес. Есть крайности, одинаково или общее среднее. Что лучше?
Корень - снизим вес наиболее активных.

Если базовая линеаризация - не смотрим на более активных пользователей. У каждого пользователя одинаковый вес
____

## Баесовская статистика и ML

![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/ab%20baes.png)

____

## Многорукие бандиты
Multi-armed bandits.
**Изменить, слишком много текста**     
Хорошо [рассписано в статье на habr](https://habr.com/ru/company/ods/blog/325416/)

Практически Reinforcement Learning - есть агент и есть среда, агент взаимодействует со средой и получает (или не получает) награду. В зависимости от этого агент корректирует свои действия, чтобы награду максимизировать. 

Допустим, хотим выбрать самые конвертящие баннеры для рекламы. Изначально каждому присваиваем равный "вес" - вероятность быть показанным пользователям. Замоделируем конверсию нашего баннера при помощи бета-распределение с $\alpha = \beta = 1$, чтобы получить равномерное распределение. Если в баннер сконвертировались, по правилу байеса можем посчитать новую, апостериорную вероятность конверсии в него (напомню, начинали с равномерного распределения). Спустя несколько таких обновлений мы уже получим новые распределения для каждого баннера, где одни будут явно лучше других. При этом мы всё ещё можем показывать слабо перформящие баннеры пользователям, но уже с меньшим весом
  

Бета распределение является [**априорно сопряженным**](https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D0%BF%D1%80%D1%8F%D0%B6%D1%91%D0%BD%D0%BD%D0%BE%D0%B5_%D0%B0%D0%BF%D1%80%D0%B8%D0%BE%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5) к распределению Бернулли, т.е. апостериорное распределение тоже имеет форму бета-распределения, но с другими параметрами:
![\Large ](https://latex.codecogs.com/svg.latex?\Large&space;Beta(\alpha+y,\beta+1-y)=Beta(\theta|\alpha,\beta)*Bernoulli(y|\theta)) 
____

## Дельта-метод

* Можно ли применять t-test для **средних**?
    - Да, так как **ЦПТ**      
* Можно ли применять t-test для **ratio** (отошение одного к другому, например конверсию считать)?
    - Да. **Дельта-метод**


https://vk.com/doc177180823_539580427?hash=001dccc97ec23a2ae3
В докладе
![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/дельта-метод.png)
![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/дельта-метод2.png)

Дополнительно: https://dl.acm.org/doi/10.1145/3219819.3219919

Доклад от вк:
https://medium.com/@vktech/practitioners-guide-to-statistical-tests-ed2d580ef04f

Все функции расписаны - просто расчет p-value, с помощью формул.
https://github.com/marnikitta/stattests/blob/master/stattests/tests.py

Формула, как считать
https://stats.stackexchange.com/questions/291594/estimation-of-population-ratio-using-delta-method/291652#291652
____

##  Техника бакетов

![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/bucket-1.png)

Бакет - быстрый бутстрап.
Дисперсия примерно сохраняется.
Можно использовать при очень большие данные.
  
Чем больше бакетов, тем меньше информации теряется, и тем меньше ошибка в равенстве. (B = 200 из доклада в Авито https://habr.com/ru/company/avito/blog/454164/)  
Слишком много данных - проблема. Слишком много, начинаем отлавливать малейшие флуктуациию. 
Бьем на несколько частей и в каждом считаем выбранную метрику.

- Плотность распределения метрики после бакетного преобразования всегда становится схожа с нормальным.
- как в бутстрепе. Бакет - корзина. 

Чем больше бакетов, тем меньше информации теряется. В Авито количество бакетов = 200.


В [стаье гугла](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43157.pdf) - если для CTR, где delta-method, описано, почему он не работает:
"Put simply, the delta method fails for massive data whenever sharding has been done in a manner inconsistent with the statistical dependence structure of the data—when the exchangeable unit is coarser than the record unit".
Не можем посчитать нормально, так как на разных серверах данные (Map-reduce).
____

## Peeking problem
Если мы очень много раз будем смотреть в результаты, то при больших значения наблюдений мы с вероятностью стремящейся к 1 (вроде не факт, что к 1, и при разных альфа разные значение. Но при альфа=0.05 вероятность больше 0.5) увидем результат: статистически значимый, даже при A/A тесте.
Асимптотика другая. Не совсем понял почему, но смысл понятен    
https://www.youtube.com/watch?v=BJwNdethKwQ

**Peeking problem** -
![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/decision%20boundaries.png)
Есть по крайней мере 4 варианта решения проблемы:
* alpha = 0,0000005
* Баесовские АБ тесты (что это?)
* Многорукие бандиты
* Sequantial test. Секвинциальное тестирование.
____

## Множественное тестирование    
1. Поправка Бонферрони.![\Large ](https://latex.codecogs.com/svg.latex?p\geq\alpha/n) 
2. Метод Холма ![\Large ](https://latex.codecogs.com/svg.latex?p_1\leq\cdots\leq{p_n})      
Затем корректируется исходно заданный ![\Large ](https://latex.codecogs.com/svg.latex?\alpha) -уровень:   
![\Large ](https://latex.codecogs.com/svg.latex?\alpha_i=\alpha{/(n-i+1)})   
после чего проверяется условие ![\Large ](https://latex.codecogs.com/svg.latex?p_i\geq\alpha_i)

Точка останова алгоритма — момент i, когда принята первая основная гипотеза ![\Large ](https://latex.codecogs.com/svg.latex?\Large&space;H_{0i}). при этом принимаются и все последующие ![\Large ](https://latex.codecogs.com/svg.latex?\Large&space;H_{0j}) , j > i    

[Множественные эксперименты: теория и практика](https://habr.com/ru/company/yandex/blog/476826/)     
____

## Бутстрап
#### Классический бутстрап
**Нужно знать n**
![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/bucket-2.png)

#### Пуасоновский бутстрап
![ph1](https://github.com/alex24816/KnowledgeBaseAB-testing/blob/main/Photos/bucket-3.png)

[Расчёт каннибализации на основе классического A/B-теста и метод bootstrap’а](https://habr.com/ru/post/451488/)

```python
from bootstrapped import bootstrap as bs
from bootstrapped import compare_functions as bs_cmp
from bootstrapped import stats_functions as bs_st
bs_ab_estims = bs.bootstrap_ab(np.array(group_A), np.array(group_B), 
                               bs_st.mean bs_cmp.difference, 
                               num_iterations=5000, alpha=0.05/3, 
                               iteration_batch_size=100, scale_test_by=1, 
                               num_threads=4)
```





```
____
```


[:arrow_up:Оглавление](#Оглавление)


